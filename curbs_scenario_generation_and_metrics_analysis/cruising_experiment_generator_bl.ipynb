{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "550859f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 65%; }\n",
       "    div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#cells will fill entire width of the browser\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))\n",
    "\n",
    "#Tells Jupyter to reload custom classes from scratch everytime an import cell is run, if you edit a custom class\n",
    "#between imports Jupyter would otherwise need to be restarted completely. Buyer beware: old class objects in the \n",
    "#current namespace will cause errors at execution\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#switches matplotlib to show plots in the browser rather than opening a new window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a7d1581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import multiprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45576e32",
   "metadata": {},
   "source": [
    "#### global simulation/read-write parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f3466e",
   "metadata": {},
   "source": [
    "give write_directory new name for new experiments, and adjust fixed/parking variables as seen fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3836587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get cores per process, can do 4 processes with standalone license\n",
    "\n",
    "cores_per_process = int(multiprocessing.cpu_count()/4) #2 simulations in parallel for 8 cores, max 4 simulations on simulateously\n",
    "use_all_cores = \"false\"\n",
    "number_of_runs_per_exp = 1\n",
    "sim_period = 9000\n",
    "sim_resolution = 10 #measurements per second\n",
    "# ^ I changed this from 10 10/13/2022!!!\n",
    "\n",
    "time_steps_per_vehicle_measurement = 10 #this means vehcile measurements per unit simulation resolution\n",
    "# ^ I changed this from 10 10/13/2022!!!\n",
    "\n",
    "# write_directory = \"E:\\\\20220511_experiments_multi_block\\\\\" #name set manually\n",
    "write_directory = \"E:\\\\20221211_experiments_Cruise1\\\\\" #name set manually \n",
    "#subdirectory\n",
    "laneconfig = \"2lane\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd8399d",
   "metadata": {},
   "source": [
    "## Scenario parameter sweep values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be69b19",
   "metadata": {},
   "source": [
    "#### Fixed values and parking variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f27bcc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check fixed for all sim driving behavior\n",
    "jerkLimit=\"false\"\n",
    "consNextTurn=\"true\"\n",
    "recovSlow=\"false\"\n",
    "recovDist=\"1000\"\n",
    "distractProb=\"0.01\"\n",
    "\n",
    "#variable across experiments\n",
    "parking_rates = [0.05, 0.10, 0.15, 0.20, 0.25, 0.3]\n",
    "speed_dists = [25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce7bca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust mean and stdDEv per distribution number, let distribution numbers be fixed for vehicleRoutingDecisionsParking\n",
    "#so each of these just maps to vehicle class, only need to worry about editting 50, 60, 70, and 80\n",
    "\n",
    "#for no 50\n",
    "bus_means = [90] #in seconds\n",
    "bus_stds = [0.25*i for i in bus_means] #each of these maps to each of the means\n",
    "bus_park_dists = zip(bus_means, bus_stds)\n",
    "\n",
    "#for no 60\n",
    "car_means = [600]\n",
    "car_stds = [0.25*i for i in car_means] #each of these maps to each of the means\n",
    "car_park_dists = zip(car_means, car_stds)\n",
    "\n",
    "#for no 70\n",
    "tnc_means = [30]\n",
    "tnc_stds = [0.25*i for i in tnc_means]\n",
    "tnc_park_dists = zip(tnc_means, tnc_stds)\n",
    "\n",
    "#HGV_dwell\n",
    "hgv_means = [300, 850]\n",
    "hgv_stds = [0.25*i for i in hgv_means]\n",
    "hgv_park_dists = zip(hgv_means, hgv_stds)\n",
    "\n",
    "#volumes\n",
    "#volumes = np.arange(150,850,100) \n",
    "\n",
    "#compositions\n",
    "#TNCcomp = np.arange(0.20,0.3,0.05)\n",
    "#CVcomp = np.arange(0.115,0.155,0.02)\n",
    "#PAXcomp = 0.935-TNCcomp-CVcomp\n",
    "#BUScomp = 0.03 #np.arange(0.03,0.03,1)\n",
    "#HGVcomp = 0.035 #np.arange(0.035,0.035,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a669f0",
   "metadata": {},
   "source": [
    "#### Vehicle volumes and compositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df2c117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#volumes = np.arange(0,500,100) #vehicles per hour\n",
    "volumes = np.arange(50,450,50) \n",
    "#super duper fancy uniform sampling from n-dim simplex Donald B. Rubin, The Bayesian bootstrap Ann. Statist. 9, 1981, 130-134.\n",
    "MC_size = 0\n",
    "num_vehicle_types = 5\n",
    "#new distributions for TNC, CV fleet composition share\n",
    "#TNCcomp = np.arange(0.20,0.3,0.05)\n",
    "#CVcomp = np.arange(0.115,0.155,0.02)\n",
    "#PAXcomp = 0.935-TNCcomp-CVcomp\n",
    "#BUScomp = np.arange(0.03,0.03,1)\n",
    "#HGVcomp = np.arange(0.035,0.035,1)\n",
    "vehicle_ratios_MC = [[0.55, 0.03, 0.035, 0.25, 0.135]] #initialize with a default sample, each decimal refers to a vehicle proporiton\n",
    "#vehicle_ratios_MC = [[PAXcomp, 0.03, 0.035, TNCcomp, CVcomp]]\n",
    "\n",
    "for i in range(MC_size):\n",
    "    #take N-1 samples from Unif(0,1), sort, compute first difference on [0, x_1, x_2, x_n-1, 1]\n",
    "    pre_ratios = [0, 1]\n",
    "    for n in range(num_vehicle_types-1):\n",
    "        pre_ratios.append(np.random.uniform(0,1))\n",
    "\n",
    "    sorted_pre_ratios = sorted(pre_ratios)\n",
    "    veh_ratios = list(np.diff(pre_ratios))\n",
    "\n",
    "    vehicle_ratios_MC.append(veh_ratios)\n",
    "    \n",
    "#ensure each vertex of the simplex is present in the sample\n",
    "#for i in range(num_vehicle_types):\n",
    "#    temp_ratios = [0 for j in range(num_vehicle_types)]\n",
    "#    temp_ratios[i] = 1.0\n",
    "#    vehicle_ratios_MC.append(temp_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5ed4817",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "              'bus_park_dists': bus_park_dists,\n",
    "              'car_park_dists': car_park_dists,\n",
    "              'tnc_park_dists': tnc_park_dists,\n",
    "              'hgv_park_dists': hgv_park_dists,\n",
    "              'vehicleVolumes': volumes,\n",
    "              'speed_dists': speed_dists,\n",
    "              'vehicleCompositions': vehicle_ratios_MC,\n",
    "              'parking_rates': parking_rates\n",
    "             }\n",
    "\n",
    "param_sweep = list(ParameterGrid(param_grid)) #each list item is a dict with a unique key-value combination of the above\n",
    "                                              #key-list pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36f01e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(param_sweep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c7efd8",
   "metadata": {},
   "source": [
    "## Populate experiment output directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b21609f",
   "metadata": {},
   "source": [
    "#### Read in scenario baseline inpx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fb6f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"C:\\\\Users\\\\maxn363\\\\Documents\\\\vissimpark\\\\\" \n",
    "scenario_dirs = os.listdir(base_path + \"VISSIM_configs\\\\atomic_network_multi_block\\\\\" + laneconfig + \"\\\\\")\n",
    "\n",
    "\n",
    "for dirname in scenario_dirs:\n",
    "    #get baseline scenario directory path, inpx path\n",
    "    scenario_path = base_path + \"VISSIM_configs\\\\atomic_network_multi_block\\\\\" + laneconfig + \"\\\\\" + dirname + \"\\\\\"\n",
    "    inpx_file_path =  scenario_path + \"Seattle_Atomic_Network_\" + dirname + \".inpx\" #this is the master simulation configuration file\n",
    "    \n",
    "    copy_files = [\"SLU-v21.sig\", \"Seattle_Atomic_network_\" + dirname + \".layx\"]\n",
    "    \n",
    "    #create experiment output directory\n",
    "    if not os.path.exists(write_directory):\n",
    "        os.mkdir(write_directory)\n",
    "    \n",
    "    outdir = write_directory + \"\\\\\" + dirname\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "        \n",
    "    #create experiment registry\n",
    "    paramfile = open(outdir + \"\\\\experiment_registry.txt\", 'w')\n",
    "    param_names = sorted(param_grid.keys()) \n",
    "    header = \"experiment_number,\" + \",\".join(param_names)\n",
    "    paramfile.write(\"header\\n\")\n",
    "    \n",
    "    #create logfile to record errors, runtimes\n",
    "    with open(outdir + \"\\\\experiment_logfile.txt\", 'w') as d:\n",
    "        d.write(\"experiment_number,runtime,stdout\\n\")\n",
    "    \n",
    "    experiment_counter = 1\n",
    "    for param_set in param_sweep:\n",
    "        values = [ str(param_set[key]) for key in param_names ]\n",
    "        paramfile.write(str(experiment_counter) + \",\" + \",\".join(values) + \"\\n\")\n",
    "        \n",
    "        #write experiment directory\n",
    "        exp_dir = outdir + \"\\\\experiment_\" + str(experiment_counter)\n",
    "        if not os.path.exists(exp_dir):\n",
    "            os.mkdir(exp_dir)\n",
    "            \n",
    "        #copy sig files, layx file\n",
    "        for file_name in copy_files:\n",
    "            full_file_name = os.path.join(scenario_path, file_name)\n",
    "            if os.path.isfile(full_file_name):\n",
    "                shutil.copy(full_file_name, exp_dir)\n",
    "        \n",
    "        #read, edit, write inpx file\n",
    "        tree = ET.parse(inpx_file_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        ###ensure fixed values are correct\n",
    "        #driving behaviors\n",
    "        for v in root.iter('drivingBehaviors'):\n",
    "            v.set('jerkLimit', 'false')\n",
    "            v.set('consNextTurn', 'true')\n",
    "            v.set('recovSlow', 'false')\n",
    "            v.set('recovDist', '1000')\n",
    "            v.set('distractProb', '0.01')\n",
    "            \n",
    "        for v in root.iter('simulation'):\n",
    "            v.set('numCores', str(cores_per_process))\n",
    "            v.set('numRuns', str(number_of_runs_per_exp))\n",
    "            v.set('useAllCores', use_all_cores)\n",
    "            v.set('simPeriod', str(sim_period))\n",
    "            v.set('randSeed', str(random.randrange(1,5000)))\n",
    "            v.set('simRes', str(sim_resolution))\n",
    "            \n",
    "        for v in root.iter('vehRec'):\n",
    "            v.set('resolution', str(time_steps_per_vehicle_measurement))\n",
    "            \n",
    "        #set warmup period for spitting out collected data\n",
    "        #ignoring vehicles already in network given toggled setting\n",
    "        warmup = '1800' #this should probably get moved up\n",
    "        for v in root.iter('dataColl'):\n",
    "            v.set('fromTime', warmup)\n",
    "            \n",
    "        for v in root.iter('dataCollRawData'):\n",
    "            v.set('fromtTime', warmup)\n",
    "            \n",
    "        for v in root.iter('vehInps'):\n",
    "            v.set('fromtTime', warmup)\n",
    "            \n",
    "        for v in root.iter('vehRec'):\n",
    "            v.set('fromtTime', warmup)\n",
    "        \n",
    "        ###edit variable values\n",
    "        #vehicle volume\n",
    "        vol = param_set['vehicleVolumes']\n",
    "        for v in root.iter('timeIntervalVehVolume'):\n",
    "            v.set('volume', str(vol))\n",
    "            \n",
    "        ###speed dist and vehicle composition\n",
    "        veh_type_counter = 0\n",
    "        vehicle_comps = param_set['vehicleCompositions']\n",
    "        for v in root.iter('vehCompRelFlows'):\n",
    "            v.set('desSpeedDistr', str(param_set['speed_dists']))\n",
    "            v.set('relFlow', str(vehicle_comps[veh_type_counter]))\n",
    "            veh_type_counter += 1\n",
    "            \n",
    "        ###parking times\n",
    "        for v in root.iter('timeDistribution'):\n",
    "            #cars\n",
    "            if v.attrib['no'] == '60':\n",
    "                v.set('mean', str(param_set['car_park_dists'][0]))\n",
    "                v.set('stdDev', str(param_set['car_park_dists'][1]))\n",
    "            #busses\n",
    "            if v.attrib['no'] == '50':\n",
    "                v.set('mean', str(param_set['bus_park_dists'][0]))\n",
    "                v.set('stdDev', str(param_set['bus_park_dists'][1]))\n",
    "            #tncs\n",
    "            if v.attrib['no'] == '70':\n",
    "                v.set('mean', str(param_set['tnc_park_dists'][0]))\n",
    "                v.set('stdDev', str(param_set['tnc_park_dists'][1]))\n",
    "            #hgv's\n",
    "            if v.attrib['no'] == '80':\n",
    "                v.set('mean', str(param_set['hgv_park_dists'][0]))\n",
    "                v.set('stdDev', str(param_set['hgv_park_dists'][1]))\n",
    "                \n",
    "        ###parking rates\n",
    "        for v in root.iter('timeIntParkRate'):\n",
    "            v.set('parkRate', str(param_set['parking_rates']))\n",
    "        \n",
    "                \n",
    "        #write final inpx file\n",
    "        tree.write(exp_dir + \"\\\\Seattle_Atomic_Network_\" + dirname + \"_experiment_\" + str(experiment_counter) + \".inpx\")\n",
    "        \n",
    "        experiment_counter += 1\n",
    "        \n",
    "    paramfile.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af908a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f0e54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3e07197",
   "metadata": {},
   "source": [
    "#### global simulation/read-write parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0092259",
   "metadata": {},
   "source": [
    "give write_directory new name for new experiments, and adjust fixed/parking variables as seen fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f247d00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get cores per process, can do 4 processes with standalone license\n",
    "\n",
    "cores_per_process = int(multiprocessing.cpu_count()/4) #2 simulations in parallel for 8 cores, max 4 simulations on simulateously\n",
    "use_all_cores = \"false\"\n",
    "number_of_runs_per_exp = 1\n",
    "sim_period = 9000\n",
    "sim_resolution = 10 #measurements per second\n",
    "# ^ I changed this from 10 10/13/2022!!!\n",
    "\n",
    "time_steps_per_vehicle_measurement = 10 #this means vehcile measurements per unit simulation resolution\n",
    "# ^ I changed this from 10 10/13/2022!!!\n",
    "\n",
    "# write_directory = \"E:\\\\20220511_experiments_multi_block\\\\\" #name set manually\n",
    "write_directory = \"E:\\\\20221211_experiments_Cruise2\\\\\" #name set manually \n",
    "#subdirectory\n",
    "laneconfig = \"Llane\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bc3e4b",
   "metadata": {},
   "source": [
    "## Scenario parameter sweep values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c495205",
   "metadata": {},
   "source": [
    "#### Fixed values and parking variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13a53a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check fixed for all sim driving behavior\n",
    "jerkLimit=\"false\"\n",
    "consNextTurn=\"true\"\n",
    "recovSlow=\"false\"\n",
    "recovDist=\"1000\"\n",
    "distractProb=\"0.01\"\n",
    "\n",
    "#variable across experiments\n",
    "parking_rates = [0.05, 0.10, 0.15, 0.20, 0.25, 0.3]\n",
    "speed_dists = [25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "749ce2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust mean and stdDEv per distribution number, let distribution numbers be fixed for vehicleRoutingDecisionsParking\n",
    "#so each of these just maps to vehicle class, only need to worry about editting 50, 60, 70, and 80\n",
    "\n",
    "#for no 50\n",
    "bus_means = [90] #in seconds\n",
    "bus_stds = [0.25*i for i in bus_means] #each of these maps to each of the means\n",
    "bus_park_dists = zip(bus_means, bus_stds)\n",
    "\n",
    "#for no 60\n",
    "car_means = [600]\n",
    "car_stds = [0.25*i for i in car_means] #each of these maps to each of the means\n",
    "car_park_dists = zip(car_means, car_stds)\n",
    "\n",
    "#for no 70\n",
    "tnc_means = [30]\n",
    "tnc_stds = [0.25*i for i in tnc_means]\n",
    "tnc_park_dists = zip(tnc_means, tnc_stds)\n",
    "\n",
    "#HGV_dwell\n",
    "hgv_means = [300, 850]\n",
    "hgv_stds = [0.25*i for i in hgv_means]\n",
    "hgv_park_dists = zip(hgv_means, hgv_stds)\n",
    "\n",
    "#volumes\n",
    "#volumes = np.arange(150,850,100) \n",
    "\n",
    "#compositions\n",
    "#TNCcomp = np.arange(0.20,0.3,0.05)\n",
    "#CVcomp = np.arange(0.115,0.155,0.02)\n",
    "#PAXcomp = 0.935-TNCcomp-CVcomp\n",
    "#BUScomp = 0.03 #np.arange(0.03,0.03,1)\n",
    "#HGVcomp = 0.035 #np.arange(0.035,0.035,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf1acad",
   "metadata": {},
   "source": [
    "#### Vehicle volumes and compositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27dfcd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#volumes = np.arange(0,500,100) #vehicles per hour\n",
    "volumes = np.arange(50,450,50) \n",
    "#super duper fancy uniform sampling from n-dim simplex Donald B. Rubin, The Bayesian bootstrap Ann. Statist. 9, 1981, 130-134.\n",
    "MC_size = 0\n",
    "num_vehicle_types = 5\n",
    "#new distributions for TNC, CV fleet composition share\n",
    "#TNCcomp = np.arange(0.20,0.3,0.05)\n",
    "#CVcomp = np.arange(0.115,0.155,0.02)\n",
    "#PAXcomp = 0.935-TNCcomp-CVcomp\n",
    "#BUScomp = np.arange(0.03,0.03,1)\n",
    "#HGVcomp = np.arange(0.035,0.035,1)\n",
    "vehicle_ratios_MC = [[0.55, 0.03, 0.035, 0.25, 0.135]] #initialize with a default sample, each decimal refers to a vehicle proporiton\n",
    "#vehicle_ratios_MC = [[PAXcomp, 0.03, 0.035, TNCcomp, CVcomp]]\n",
    "\n",
    "for i in range(MC_size):\n",
    "    #take N-1 samples from Unif(0,1), sort, compute first difference on [0, x_1, x_2, x_n-1, 1]\n",
    "    pre_ratios = [0, 1]\n",
    "    for n in range(num_vehicle_types-1):\n",
    "        pre_ratios.append(np.random.uniform(0,1))\n",
    "\n",
    "    sorted_pre_ratios = sorted(pre_ratios)\n",
    "    veh_ratios = list(np.diff(pre_ratios))\n",
    "\n",
    "    vehicle_ratios_MC.append(veh_ratios)\n",
    "    \n",
    "#ensure each vertex of the simplex is present in the sample\n",
    "#for i in range(num_vehicle_types):\n",
    "#    temp_ratios = [0 for j in range(num_vehicle_types)]\n",
    "#    temp_ratios[i] = 1.0\n",
    "#    vehicle_ratios_MC.append(temp_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5426facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "              'bus_park_dists': bus_park_dists,\n",
    "              'car_park_dists': car_park_dists,\n",
    "              'tnc_park_dists': tnc_park_dists,\n",
    "              'hgv_park_dists': hgv_park_dists,\n",
    "              'vehicleVolumes': volumes,\n",
    "              'speed_dists': speed_dists,\n",
    "              'vehicleCompositions': vehicle_ratios_MC,\n",
    "              'parking_rates': parking_rates\n",
    "             }\n",
    "\n",
    "param_sweep = list(ParameterGrid(param_grid)) #each list item is a dict with a unique key-value combination of the above\n",
    "                                              #key-list pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6ea018d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(param_sweep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2fb5cf",
   "metadata": {},
   "source": [
    "## Populate experiment output directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf250dc",
   "metadata": {},
   "source": [
    "#### Read in scenario baseline inpx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28a1f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"C:\\\\Users\\\\maxn363\\\\Documents\\\\vissimpark\\\\\" \n",
    "scenario_dirs = os.listdir(base_path + \"VISSIM_configs\\\\atomic_network_multi_block\\\\\" + laneconfig + \"\\\\\")\n",
    "\n",
    "\n",
    "for dirname in scenario_dirs:\n",
    "    #get baseline scenario directory path, inpx path\n",
    "    scenario_path = base_path + \"VISSIM_configs\\\\atomic_network_multi_block\\\\\" + laneconfig + \"\\\\\" + dirname + \"\\\\\"\n",
    "    inpx_file_path =  scenario_path + \"Seattle_Atomic_Network_\" + dirname + \".inpx\" #this is the master simulation configuration file\n",
    "    \n",
    "    copy_files = [\"SLU-v21.sig\", \"Seattle_Atomic_network_\" + dirname + \".layx\"]\n",
    "    \n",
    "    #create experiment output directory\n",
    "    if not os.path.exists(write_directory):\n",
    "        os.mkdir(write_directory)\n",
    "    \n",
    "    outdir = write_directory + \"\\\\\" + dirname\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "        \n",
    "    #create experiment registry\n",
    "    paramfile = open(outdir + \"\\\\experiment_registry.txt\", 'w')\n",
    "    param_names = sorted(param_grid.keys()) \n",
    "    header = \"experiment_number,\" + \",\".join(param_names)\n",
    "    paramfile.write(\"header\\n\")\n",
    "    \n",
    "    #create logfile to record errors, runtimes\n",
    "    with open(outdir + \"\\\\experiment_logfile.txt\", 'w') as d:\n",
    "        d.write(\"experiment_number,runtime,stdout\\n\")\n",
    "    \n",
    "    experiment_counter = 1\n",
    "    for param_set in param_sweep:\n",
    "        values = [ str(param_set[key]) for key in param_names ]\n",
    "        paramfile.write(str(experiment_counter) + \",\" + \",\".join(values) + \"\\n\")\n",
    "        \n",
    "        #write experiment directory\n",
    "        exp_dir = outdir + \"\\\\experiment_\" + str(experiment_counter)\n",
    "        if not os.path.exists(exp_dir):\n",
    "            os.mkdir(exp_dir)\n",
    "            \n",
    "        #copy sig files, layx file\n",
    "        for file_name in copy_files:\n",
    "            full_file_name = os.path.join(scenario_path, file_name)\n",
    "            if os.path.isfile(full_file_name):\n",
    "                shutil.copy(full_file_name, exp_dir)\n",
    "        \n",
    "        #read, edit, write inpx file\n",
    "        tree = ET.parse(inpx_file_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        ###ensure fixed values are correct\n",
    "        #driving behaviors\n",
    "        for v in root.iter('drivingBehaviors'):\n",
    "            v.set('jerkLimit', 'false')\n",
    "            v.set('consNextTurn', 'true')\n",
    "            v.set('recovSlow', 'false')\n",
    "            v.set('recovDist', '1000')\n",
    "            v.set('distractProb', '0.01')\n",
    "            \n",
    "        for v in root.iter('simulation'):\n",
    "            v.set('numCores', str(cores_per_process))\n",
    "            v.set('numRuns', str(number_of_runs_per_exp))\n",
    "            v.set('useAllCores', use_all_cores)\n",
    "            v.set('simPeriod', str(sim_period))\n",
    "            v.set('randSeed', str(random.randrange(1,5000)))\n",
    "            v.set('simRes', str(sim_resolution))\n",
    "            \n",
    "        for v in root.iter('vehRec'):\n",
    "            v.set('resolution', str(time_steps_per_vehicle_measurement))\n",
    "            \n",
    "        #set warmup period for spitting out collected data\n",
    "        #ignoring vehicles already in network given toggled setting\n",
    "        warmup = '1800' #this should probably get moved up\n",
    "        for v in root.iter('dataColl'):\n",
    "            v.set('fromTime', warmup)\n",
    "            \n",
    "        for v in root.iter('dataCollRawData'):\n",
    "            v.set('fromtTime', warmup)\n",
    "            \n",
    "        for v in root.iter('vehInps'):\n",
    "            v.set('fromtTime', warmup)\n",
    "            \n",
    "        for v in root.iter('vehRec'):\n",
    "            v.set('fromtTime', warmup)\n",
    "        \n",
    "        ###edit variable values\n",
    "        #vehicle volume\n",
    "        vol = param_set['vehicleVolumes']\n",
    "        for v in root.iter('timeIntervalVehVolume'):\n",
    "            v.set('volume', str(vol))\n",
    "            \n",
    "        ###speed dist and vehicle composition\n",
    "        veh_type_counter = 0\n",
    "        vehicle_comps = param_set['vehicleCompositions']\n",
    "        for v in root.iter('vehCompRelFlows'):\n",
    "            v.set('desSpeedDistr', str(param_set['speed_dists']))\n",
    "            v.set('relFlow', str(vehicle_comps[veh_type_counter]))\n",
    "            veh_type_counter += 1\n",
    "            \n",
    "        ###parking times\n",
    "        for v in root.iter('timeDistribution'):\n",
    "            #cars\n",
    "            if v.attrib['no'] == '60':\n",
    "                v.set('mean', str(param_set['car_park_dists'][0]))\n",
    "                v.set('stdDev', str(param_set['car_park_dists'][1]))\n",
    "            #busses\n",
    "            if v.attrib['no'] == '50':\n",
    "                v.set('mean', str(param_set['bus_park_dists'][0]))\n",
    "                v.set('stdDev', str(param_set['bus_park_dists'][1]))\n",
    "            #tncs\n",
    "            if v.attrib['no'] == '70':\n",
    "                v.set('mean', str(param_set['tnc_park_dists'][0]))\n",
    "                v.set('stdDev', str(param_set['tnc_park_dists'][1]))\n",
    "            #hgv's\n",
    "            if v.attrib['no'] == '80':\n",
    "                v.set('mean', str(param_set['hgv_park_dists'][0]))\n",
    "                v.set('stdDev', str(param_set['hgv_park_dists'][1]))\n",
    "                \n",
    "        ###parking rates\n",
    "        for v in root.iter('timeIntParkRate'):\n",
    "            v.set('parkRate', str(param_set['parking_rates']))\n",
    "        \n",
    "                \n",
    "        #write final inpx file\n",
    "        tree.write(exp_dir + \"\\\\Seattle_Atomic_Network_\" + dirname + \"_experiment_\" + str(experiment_counter) + \".inpx\")\n",
    "        \n",
    "        experiment_counter += 1\n",
    "        \n",
    "    paramfile.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9b1d190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0bd3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be2fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9b14a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfebc7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
